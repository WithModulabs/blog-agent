import json

import streamlit as st
from typing import List, TypedDict

from langchain_core.messages import BaseMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_tavily import TavilySearch
from langgraph.graph import StateGraph, END
from openai import OpenAI

from tools import get_llm, scrape_web_content, generate_image_with_gemini


class AgentState(TypedDict):
    url: str
    scraped_content: str
    seo_analysis: str
    seo_tags: List[str]
    draft_post: str
    final_title: str
    final_subheadings: List[str]
    naver_seo_subtitles: List[str]
    image_prompt: str
    image_url: str
    blog_index: int
    blog_details: str
    subtitle_image_prompts: List[str]
    subtitle_image_urls: List[str]
    image_keywords: List[str]
    needs_rewrite: bool
    rewrite_reason: str
    rewrite_count: int  # ì¬ì‘ì„± íšŸìˆ˜ ì¶”ê°€
    messages: List[BaseMessage]


def researcher_node(state: AgentState):
    st.write("â–¶ï¸ ë¦¬ì„œì²˜ ì—ì´ì „íŠ¸: URL ì½˜í…ì¸  ë¶„ì„ ì‹œì‘...")
    url = state['url']
    title, text = scrape_web_content(url)
    scraped_content = (title or "") + (text or "")
    failure_keywords = ["ì˜¤ë¥˜ ë°œìƒ", "ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤", "ìŠ¤í¬ë©ì´ ê¸ˆì§€ëœ ê¸€"] 
    if any(k in scraped_content for k in failure_keywords):
        st.error(f"âš ï¸ {scraped_content}")
        return {"scraped_content": f"ë¶„ì„ ì‹¤íŒ¨: {scraped_content}"}
    st.success("âœ… ë¦¬ì„œì²˜ ì—ì´ì „íŠ¸: ì½˜í…ì¸  ë¶„ì„ ì™„ë£Œ!")
    return {
        "scraped_content": scraped_content,
        "messages": [HumanMessage(content=f"URL '{url}'ì˜ ì½˜í…ì¸  ë¶„ì„ ì™„ë£Œ.")]
    }


def seo_specialist_node(state: AgentState):
    st.write("â–¶ï¸ SEO ì „ë¬¸ê°€ ì—ì´ì „íŠ¸: ë„¤ì´ë²„ SEO ì „ëµ ë¶„ì„ ì¤‘...")
    scraped_content = state['scraped_content']
    search_query = "2025ë…„ ë„¤ì´ë²„ ë¸”ë¡œê·¸ SEO ìµœì í™” ì „ëµ"
    tavily_api_key = st.session_state.get("tavily_api_key")
    if not tavily_api_key:
        st.error("âŒ Tavily API Keyê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return {"scraping_status": "Failure", "seo_analysis": "Tavily API Key ì—†ìŒ", "seo_tags": []}

    try:
        tavily = TavilySearch(max_results=3, tavily_api_key=tavily_api_key)
        results = tavily.invoke({"query": search_query})
        seo_trends = ""
        if results and "results" in results:
            for r in results["results"]:
                seo_trends += f"ì œëª©: {r.get('title','')}\në‚´ìš©: {r.get('content','')}\n\n"
        else:
            seo_trends = "ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        st.error(f"Tavily ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        seo_trends = ""

    prompt = ChatPromptTemplate.from_messages([
        ("system",
         """ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ ë„¤ì´ë²„ ë¸”ë¡œê·¸ SEO ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
         ì£¼ì–´ì§„ ì›ë³¸ ì½˜í…ì¸ ì™€ ìµœì‹  SEO íŠ¸ë Œë“œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë„¤ì´ë²„ ê²€ìƒ‰ì— ìµœì í™”ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì „ëµì„ ìˆ˜ë¦½í•´ì•¼ í•©ë‹ˆë‹¤.
         ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:
         [ë¶„ì„ ë° ì „ëµ]
         - (ì—¬ê¸°ì— ì½˜í…ì¸  ê¸°ë°˜ SEO ì „ëµê³¼ í‚¤ì›Œë“œ ë¶„ì„ ë‚´ìš©ì„ ì„œìˆ )
         
         [ì¶”ì²œ íƒœê·¸]
         íƒœê·¸1, íƒœê·¸2, íƒœê·¸3, ... (ì‰¼í‘œë¡œ êµ¬ë¶„ëœ 30ê°œì˜ íƒœê·¸)"""),
        ("human",
         "**ìµœì‹  ë„¤ì´ë²„ SEO íŠ¸ë Œë“œ:**\n{seo_trends}\n\n"
         "**ë¶„ì„í•  ì›ë³¸ ì½˜í…ì¸ :**\n{scraped_content}")
    ])

    llm = get_llm()
    if llm is None:
        return {"scraping_status": "Failure", "seo_analysis": "LLM ì—†ìŒ", "seo_tags": []}

    chain = prompt | llm
    resp = chain.invoke({"seo_trends": seo_trends, "scraped_content": scraped_content[:4000]})
    analysis_text = resp.content
    try:
        tags_part = analysis_text.split("[ì¶”ì²œ íƒœê·¸]")[1].strip()
        tags = [t.strip() for t in tags_part.split(",") if t.strip()]
    except IndexError:
        tags = []

    st.success("âœ… SEO ì „ë¬¸ê°€ ì—ì´ì „íŠ¸: ì „ëµ ë¶„ì„ ë° íƒœê·¸ ìƒì„± ì™„ë£Œ!")
    return {"seo_analysis": analysis_text, "seo_tags": tags}


def writer_node(state: AgentState):
    # ì¬ì‘ì„± ì—¬ë¶€ í™•ì¸
    is_rewrite = state.get("needs_rewrite", False)
    rewrite_count = state.get("rewrite_count", 0)
    
    if is_rewrite:
        st.write(f"â–¶ï¸ ì‘ì„±ê°€ ì—ì´ì „íŠ¸: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì¬ì‘ì„± ì¤‘... ({rewrite_count + 1}íšŒì°¨)")
    else:
        st.write("â–¶ï¸ ì‘ì„±ê°€ ì—ì´ì „íŠ¸: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì´ˆì•ˆ ì‘ì„± ì¤‘...")
    
    scraped_content = state['scraped_content']
    seo_analysis = state['seo_analysis']
    rewrite_reason = state.get('rewrite_reason', '')

    title_prompt = ChatPromptTemplate.from_template(
        "ì£¼ì–´ì§„ SEO ë¶„ì„ê³¼ ì›ë³¸ ì½˜í…ì¸ ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë„¤ì´ë²„ ê²€ìƒ‰ì— ìµœì í™”ëœ ë§¤ë ¥ì ì¸ ë¸”ë¡œê·¸ ì œëª© 1ê°œë§Œ ìƒì„±í•´ì£¼ì„¸ìš”. (ì¶”ê°€ ì„¤ëª… ì—†ì´ ì œëª©ë§Œ ì¶œë ¥)\n\n"
        "**SEO ë¶„ì„:**\n{seo_analysis}\n\n"
        "**ì›ë³¸ ì½˜í…ì¸ :**\n{scraped_content}"
    )
    llm = get_llm()
    if llm is None:
        return {"draft_post": "LLM ì—†ìŒ", "final_title": "", "final_subheadings": [], "naver_seo_subtitles": []}

    title_chain = title_prompt | llm
    main_title = title_chain.invoke({
        "seo_analysis": seo_analysis,
        "scraped_content": scraped_content[:2000]
    }).content.strip().replace('"', '')

    subtitle_prompt = ChatPromptTemplate.from_template(
        """ë‹¤ìŒ ë¸”ë¡œê·¸ ì œëª©ê³¼ SEO ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, ë„¤ì´ë²„ ë¸”ë¡œê·¸ SEOì— ìµœì í™”ëœ ë¶€ì œëª© 5ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        
        **ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë¶€ì œëª© ì‘ì„± ê°€ì´ë“œ:**
        - ê²€ìƒ‰ í‚¤ì›Œë“œ ìì—°ìŠ¤ëŸ¬ìš´ í¬í•¨
        - í´ë¦­ì„ ìœ ë„í•˜ëŠ” ë¬¸êµ¬
        - ìˆ«ì/ì‹œê°„ í‘œí˜„ í™œìš©
        - ê°ì •ì /í˜¸ê¸°ì‹¬ ìœ ë°œ ìš”ì†Œ
        - 20-30ì ë‚´ì™¸
        - ì„œë¡œ ë‹¤ë¥¸ ê´€ì 

        ê° ë¶€ì œëª©ì€ í•œ ì¤„ì”© ë²ˆí˜¸ ì—†ì´ ì¶œë ¥í•˜ì„¸ìš”.
        
        **ë©”ì¸ ì œëª©:** {main_title}
        
        **SEO ë¶„ì„:**
        {seo_analysis}"""
    )
    subtitle_chain = subtitle_prompt | llm
    subtitle_resp = subtitle_chain.invoke({"main_title": main_title, "seo_analysis": seo_analysis}).content
    naver_seo_subtitles = [ln.strip() for ln in subtitle_resp.split("\n") if ln.strip() and not ln.strip().startswith("**")]

    # ì¬ì‘ì„±ì¼ ê²½ìš° ê°œì„ ì‚¬í•­ì„ ë°˜ì˜í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
    if is_rewrite and rewrite_reason:
        draft_prompt = ChatPromptTemplate.from_messages([
            ("system", 
             """ë‹¹ì‹ ì€ ì „ë¬¸ ë¸”ë¡œê·¸ ì‘ê°€ì…ë‹ˆë‹¤. ì´ì „ì— ì‘ì„±í•œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ í’ˆì§ˆì´ ë‚®ì•„ì„œ ì¬ì‘ì„±ì„ ì§„í–‰í•©ë‹ˆë‹¤. 60ì  ì´ìƒì˜ ì ìˆ˜ë¥¼ ë°›ë„ë¡ ê¸€ì„ ì¬ì‘ì„±í•´ì£¼ì„¸ìš”.
             
             ë‹¤ìŒ ê°œì„ ì‚¬í•­ë“¤ì„ ë°˜ì˜í•˜ì—¬ ê³ í’ˆì§ˆì˜ ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:
             - ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ í™œìš©í•˜ì—¬ ì¹œê·¼í•œ ì–´ì¡° ìœ ì§€
             - ì„œë¡ , ë³¸ë¡ (ì†Œì œëª© ## ì‚¬ìš©), ê²°ë¡ ìœ¼ë¡œ êµ¬ì„±
             - ë…ì ê³µê° í¬ì¸íŠ¸ì™€ ì‹¤ì œ ê²½í—˜ë‹´ í¬í•¨
             - ê²€ìƒ‰ ìµœì í™”ë¥¼ ìœ„í•œ í‚¤ì›Œë“œ ìì—°ìŠ¤ëŸ½ê²Œ ë°°ì¹˜
             - ëª©ë¡ê³¼ ë²ˆí˜¸ë¥¼ í™œìš©í•˜ì—¬ ê°€ë…ì„± ê°•í™”
             - CTA(Call to Action) ì‚½ì…í•˜ì—¬ ë…ì ì°¸ì—¬ ìœ ë„
             
             **ê°œì„ í•´ì•¼ í•  ë¶€ë¶„:**
             {rewrite_reason}"""),
            ("human", "**ì œëª©:** {main_title}\n\n**SEO ë¶„ì„:**\n{seo_analysis}\n\n**ì›ë³¸ ì½˜í…ì¸ :**\n{scraped_content}")
        ])
    else:
        draft_prompt = ChatPromptTemplate.from_messages([
            ("system", "ë‹¹ì‹ ì€ ì „ë¬¸ ë¸”ë¡œê·¸ ì‘ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì œëª©, SEO ë¶„ì„, ì›ë³¸ ì½˜í…ì¸ ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ì¹œê·¼í•œ ì–´ì¡°ì˜ ë§¤ë ¥ì ì¸ ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ë‚´ìš©ì€ ì„œë¡ , ë³¸ë¡ (ì†Œì œëª© ## ì‚¬ìš©), ê²°ë¡ ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”."),
            ("human", "**ì œëª©:** {main_title}\n\n**SEO ë¶„ì„:**\n{seo_analysis}\n\n**ì›ë³¸ ì½˜í…ì¸ :**\n{scraped_content}")
        ])

    draft_chain = draft_prompt | llm
    draft_context = {
        "main_title": main_title,
        "seo_analysis": seo_analysis,
        "scraped_content": scraped_content[:4000]
    }
    if is_rewrite and rewrite_reason:
        draft_context["rewrite_reason"] = rewrite_reason

    draft_post = draft_chain.invoke(draft_context).content

    subheadings = [ln.replace("## ", "").strip() for ln in draft_post.split("\n") if ln.startswith("## ")]

    # ì¬ì‘ì„± ìƒíƒœ ì—…ë°ì´íŠ¸
    result = {
        "draft_post": draft_post,
        "final_title": main_title,
        "final_subheadings": subheadings,
        "naver_seo_subtitles": naver_seo_subtitles,
        "needs_rewrite": False,  # ì¬ì‘ì„± í”Œë˜ê·¸ ì´ˆê¸°í™”
        "rewrite_reason": ""  # ì¬ì‘ì„± ì´ìœ  ì´ˆê¸°í™”
    }
    
    if is_rewrite:
        result["rewrite_count"] = rewrite_count + 1
        st.success("âœ… ì‘ì„±ê°€ ì—ì´ì „íŠ¸: í¬ìŠ¤íŠ¸ ì¬ì‘ì„± ì™„ë£Œ!")
    else:
        result["rewrite_count"] = 0
        st.success("âœ… ì‘ì„±ê°€ ì—ì´ì „íŠ¸: í¬ìŠ¤íŠ¸ ì´ˆì•ˆ ì‘ì„± ì™„ë£Œ!")
    
    return result


def blog_indexer_node(state: AgentState):
    """ë¸”ë¡œê·¸ ì§€ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ì—ì´ì „íŠ¸"""
    st.write("â–¶ï¸ ë¸”ë¡œê·¸ ì§€ìˆ˜ ì—ì´ì „íŠ¸")
    st.success("âœ… ë¸”ë¡œê·¸ ì§€ìˆ˜ ê³„ì‚° ì¤‘...")

    draft_post = state["draft_post"]

    prompt = ChatPromptTemplate.from_messages([
        ("system", """ë‹¹ì‹ ì€ ë¸”ë¡œê·¸ ì½˜í…ì¸  ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ì„ ë¶„ì„í•˜ì—¬ ë¸”ë¡œê·¸ ì§€ìˆ˜(Blog Index)ë¥¼ ê³„ì‚°í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ 10ê°œ í•­ëª©ì„ ê°ê° 0-10ì ìœ¼ë¡œ í‰ê°€í•˜ì—¬ ì´ 100ì  ë§Œì ìœ¼ë¡œ ì±„ì í•˜ê³ , ê° í•­ëª©ë³„ í‰ê°€ ê·¼ê±°ì™€ ê°œì„ ì ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

## í‰ê°€ ê¸°ì¤€

### 1. ê²€ìƒ‰ ìµœì í™” ì œëª© ì‘ì„± 
- í•µì‹¬ í‚¤ì›Œë“œê°€ ì•ë¶€ë¶„ì— ìœ„ì¹˜í•˜ëŠ”ê°€? 
- ìˆ«ì, ì‹œê°„, ì§€ì—­ëª…ì„ í™œìš©í–ˆëŠ”ê°€? 
- í´ë¦­ì„ ìœ ë„í•˜ëŠ” ê°ì • ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€? 

### 2. ì²« ë¬¸ë‹¨ì—ì„œ í•µì‹¬ ìš”ì•½ 
- 3ì¤„ ì´ë‚´ì— ê¸€ ì „ì²´ë¥¼ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬ë˜ì—ˆëŠ”ê°€? 
- ì§ˆë¬¸í˜•ìœ¼ë¡œ ì‹œì‘í•˜ì—¬ í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ”ê°€? 

### 3. ë…ì ê³µê° í¬ì¸íŠ¸ í™•ë³´ 
- ì‹¤ì œ ì‚¬ë¡€, ê²½í—˜ë‹´, ì—í”¼ì†Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€? 
- "ì €ë„ ì²˜ìŒì—” ëª°ëëŠ”ë°â€¦" ê°™ì€ í†¤ìœ¼ë¡œ ì‹ ë¢°ê°ì„ í˜•ì„±í•˜ëŠ”ê°€? 

### 4. ë³¸ë¬¸ êµ¬ì¡°í™” 
- ì†Œì œëª©ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€? 
- ëª©ë¡/ë²ˆí˜¸ë¥¼ í™œìš©í•˜ì—¬ ê°€ë…ì„±ì„ ê°•í™”í–ˆëŠ”ê°€? 
- ê¸´ ë¬¸ì¥ì„ 2~3ì¤„ë¡œ ëŠì–´ ì¼ëŠ”ê°€? 

### 5. ê¾¸ì¤€í•œ êµ¬ë…ì ìœ ì…ì„ ìœ„í•œ ì‹œë¦¬ì¦ˆí™” 
- ë‹¨ë°œì„±ì´ ì•„ë‹Œ ì—°ì¬ ì‹œë¦¬ì¦ˆë¡œ êµ¬ì„±ë˜ì—ˆëŠ”ê°€? 
- ì˜ˆ: "ì´ˆë³´ìë¥¼ ìœ„í•œ â—‹â—‹ 1í¸", "ì‹¤ì „ ì‘ìš© 2í¸"

### 6. ë‚´ë¶€ ë§í¬ & ì™¸ë¶€ ë§í¬ ì „ëµ 
- ë¸”ë¡œê·¸ ë‚´ ë‹¤ë¥¸ ê¸€ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ì–´ ìˆëŠ”ê°€? 
- ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì™¸ë¶€ ì¶œì²˜ 1~2ê°œ ì¸ìš©

### 7. ì´ë¯¸ì§€ í™œìš©ë²• 
- ê¸€ë‹¹ ìµœì†Œ 3ì¥ ì´ìƒì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í–ˆëŠ”ê°€? 
- í•µì‹¬ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ê·¸ë¦¼ íŒŒì¼ëª…ì„ ì‘ì„±í–ˆëŠ”ê°€? 
- ALT í…ìŠ¤íŠ¸ì— ì„¤ëª…ì„ ì¶”ê°€í–ˆëŠ”ê°€? 

### 8. CTA(Call To Action) ì‚½ì… 
- ê³µê°/êµ¬ë…/ì´ì›ƒì¶”ê°€ë¥¼ ìœ ë„í•˜ëŠ” ë¬¸êµ¬ê°€ ìˆëŠ”ê°€? 
- ëŒ“ê¸€ì„ ìœ ë„í•˜ëŠ” ì§ˆë¬¸ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€? 

### 9. ë©”íƒ€ë°ì´í„°ì™€ íƒœê·¸ ìµœì í™” 
- ê¸€ì˜ ì¹´í…Œê³ ë¦¬, í•´ì‹œíƒœê·¸ê°€ í‚¤ì›Œë“œì™€ ì¼ì¹˜í•˜ëŠ”ê°€? 
- ë¶ˆí•„ìš”í•œ íƒœê·¸ ë‚¨ë°œì€ í”¼í•˜ê³  í•µì‹¬ í‚¤ì›Œë“œ 3~5ê°œë§Œ ì§‘ì¤‘í•˜ì—¬ íƒœê·¸ë¥¼ ì„¤ì •í–ˆëŠ”ê°€?

### 10. ì½˜í…ì¸  ì°¨ë³„í™” ìš”ì†Œ ì¶”ê°€ 
- ì§ì ‘ ì´¬ì˜í•œ ì‚¬ì§„, ì¸í¬ê·¸ë˜í”½, í‘œ, ì°¨íŠ¸ë¥¼ í™œìš©í–ˆëŠ”ê°€? 
- ë‹¨ìˆœ ìš”ì•½í˜•ì´ ì•„ë‹Œ ê²½í—˜+ì¸ì‚¬ì´íŠ¸ë¥¼ ë‹´ì•„ ë…ì°½ì„±ì„ ê°•í™”í–ˆëŠ”ê°€? 

## ì¶œë ¥ í˜•ì‹
ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”:

í‰ê°€ ê¸°ì¤€ 1: [ì ìˆ˜]/10 - [í‰ê°€ ì´ìœ ]
í‰ê°€ ê¸°ì¤€ 2: [ì ìˆ˜]/10 - [í‰ê°€ ì´ìœ ]
...
í‰ê°€ ê¸°ì¤€ 10: [ì ìˆ˜]/10 - [í‰ê°€ ì´ìœ ]
ì´ì : [ì´ì ]/100

ìœ„ì˜ í‰ê°€ ê¸°ì¤€ì— ë”°ë¼ ì£¼ì–´ì§„ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ì„ ë¶„ì„í•˜ê³ , ê° í•­ëª©ë³„ë¡œ ìƒì„¸í•œ í‰ê°€ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""),
        ("human", "ë‹¤ìŒ ë¸”ë¡œê·¸ ê²Œì‹œë¬¼ì˜ ë¸”ë¡œê·¸ ì§€ìˆ˜ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{draft_post}")
    ])

    llm = get_llm()
    if llm is None:
        return {"blog_index": 0, "blog_details": "LLM ì´ˆê¸°í™” ì‹¤íŒ¨"}

    try:
        chain = prompt | llm
        response = chain.invoke({"draft_post": draft_post})
        
        content = response.content
        
        # ì´ì  ì¶”ì¶œ
        total_score = 0
        if "ì´ì :" in content:
            total_part = content.split("ì´ì :")[1].split("/")[0].strip()
            try:
                total_score = int(total_part)
            except:
                total_score = 0

        st.success(f"âœ… ë¸”ë¡œê·¸ ì§€ìˆ˜ ê³„ì‚° ì™„ë£Œ. {total_score}ì ")
        return {
            "blog_index": total_score,
            "blog_details": content
        }

    except Exception as e:
        st.error(f"âŒ ë¸”ë¡œê·¸ ì§€ìˆ˜ ê³„ì‚°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
        return {"blog_index": 0, "blog_details": f"ê³„ì‚° ì‹¤íŒ¨: {str(e)}"}


def art_director_node(state: AgentState):
    st.write("â–¶ï¸ ì•„íŠ¸ ë””ë ‰í„° ì—ì´ì „íŠ¸: ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
    title = state['final_title']
    subtitles = state.get('naver_seo_subtitles', [])
    image_model_provider = st.session_state.get("image_model_provider", "DALLÂ·E 3")

    # ëª¨ë¸ë³„ API í‚¤ í™•ì¸
    if image_model_provider == "DALLÂ·E 3" and not st.session_state.get("openai_api_key"):
        st.warning("âš ï¸ DALLÂ·E 3 ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•´ì„œëŠ” OpenAI API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return {"image_prompt": "", "image_url": "", "subtitle_image_prompts": [], "subtitle_image_urls": [], "image_keywords": []}
    elif image_model_provider == "Gemini 2.5 Flash Image" and not st.session_state.get("gemini_api_key"):
        st.warning("âš ï¸ Gemini ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•´ì„œëŠ” Google API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return {"image_prompt": "", "image_url": "", "subtitle_image_prompts": [], "subtitle_image_urls": [], "image_keywords": []}

    prompt_llm = get_llm()
    if prompt_llm is None:
        return {"image_prompt": "", "image_url": "", "subtitle_image_prompts": [], "subtitle_image_urls": [], "image_keywords": []}

    keyword_t = ChatPromptTemplate.from_template(
        "ë‹¤ìŒ ë¸”ë¡œê·¸ ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ 2ê°œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ì–¸ë”ìŠ¤ì½”ì–´(_)ë¡œ ì—°ê²°í•´ì„œ ì¶œë ¥í•˜ì„¸ìš”.\nì˜ˆ: 'ë§›ì§‘_í›„ê¸°' ë˜ëŠ” 'ì—¬í–‰_íŒ'\nì œëª©: {title}"
    )
    kw_chain = keyword_t | prompt_llm
    kw_resp = kw_chain.invoke({"title": title}).content.strip()
    image_keywords = [k.strip() for k in kw_resp.split("_")[:2]]

    try:
        st.write("  ğŸ“¸ ë©”ì¸ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
        main_t = ChatPromptTemplate.from_template("ë¸”ë¡œê·¸ ì œëª© '{title}'ì— ì–´ìš¸ë¦¬ëŠ” ì´ë¯¸ì§€ ìƒì„±ìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜.")
        main_chain = main_t | prompt_llm
        main_prompt = main_chain.invoke({"title": title}).content

        # ì´ë¯¸ì§€ ìƒì„± (ëª¨ë¸ë³„ ë¶„ê¸°)
        main_url = ""
        if image_model_provider == "DALLÂ·E 3":
            client = OpenAI(api_key=st.session_state.get("openai_api_key"))
            main_res = client.images.generate(model="dall-e-3", prompt=main_prompt, size="1024x1024", quality="standard", n=1)
            main_url = main_res.data[0].url

        st.write("  ğŸ¨ ë¶€ì œëª© ê¸°ë°˜ ì´ë¯¸ì§€ 3ê°œ ìƒì„± ì¤‘...")
        sub_prompts, sub_urls = [], []
        for i, sub in enumerate(subtitles[:3], 1):
            st.write(f"    â€¢ ì´ë¯¸ì§€ {i+1} ìƒì„± ì¤‘...")
            sub_t = ChatPromptTemplate.from_template("ë¸”ë¡œê·¸ ë¶€ì œëª© '{subtitle}'ì— ì–´ìš¸ë¦¬ëŠ” ì´ë¯¸ì§€ ìƒì„±ìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜.")
            sub_chain = sub_t | prompt_llm
            sub_prompt = sub_chain.invoke({"subtitle": sub}).content
            sub_prompts.append(sub_prompt)
            
            # ë¶€ì œëª© ì´ë¯¸ì§€ ìƒì„± (ëª¨ë¸ë³„ ë¶„ê¸°)
            sub_url = ""
            if image_model_provider == "DALLÂ·E 3":
                sub_res = client.images.generate(model="dall-e-3", prompt=sub_prompt, size="1024x1024", quality="standard", n=1)
                sub_url = sub_res.data[0].url
            
            sub_urls.append(sub_url)

        generated_count = sum(1 for url in [main_url] + sub_urls if url)
        st.success(f"âœ… ì•„íŠ¸ ë””ë ‰í„° ì—ì´ì „íŠ¸: {generated_count}ê°œ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!")
        return {
            "image_prompt": main_prompt,
            "image_url": main_url,
            "subtitle_image_prompts": sub_prompts,
            "subtitle_image_urls": sub_urls,
            "image_keywords": image_keywords
        }

    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        return {
            "image_prompt": locals().get("main_prompt", ""),
            "image_url": "",
            "subtitle_image_prompts": [],
            "subtitle_image_urls": [],
            "image_keywords": image_keywords
        }


def should_continue_from_researcher(state: AgentState):
    """ë¦¬ì„œì²˜ ë…¸ë“œ ì´í›„ ë¶„ê¸°"""
    if "ë¶„ì„ ì‹¤íŒ¨:" in state.get('scraped_content', ''):
        return "end_process"
    else:
        return "continue_to_seo"


def should_continue_from_indexer(state: AgentState):
    """ë¸”ë¡œê·¸ ì§€ìˆ˜ ë…¸ë“œ ì´í›„ ë¶„ê¸°"""
    blog_index = state.get("blog_index", 0)
    rewrite_count = state.get("rewrite_count", 0)
    
    # ì¬ì‘ì„± ìš”ì²­ì´ ìˆê³ , ì¬ì‘ì„± íšŸìˆ˜ê°€ 2íšŒ ë¯¸ë§Œì´ê³ , ì ìˆ˜ê°€ 60ì  ì´í•˜ì¸ ê²½ìš°
    if (state.get("needs_rewrite", False) and 
        rewrite_count < 2 and  # ìµœëŒ€ 2íšŒê¹Œì§€ë§Œ ì¬ì‘ì„±
        blog_index <= 60):
        return "rewrite_post"
    
    # ê·¸ ì™¸ì˜ ê²½ìš°ëŠ” ì•„íŠ¸ ë””ë ‰í„°ë¡œ ì§„í–‰
    return "continue_to_art"


def build_graph():
    workflow = StateGraph(AgentState)
    workflow.add_node("researcher", researcher_node)
    workflow.add_node("seo_specialist", seo_specialist_node)
    workflow.add_node("writer", writer_node)
    workflow.add_node("art_director", art_director_node)
    workflow.add_node("blog_indexer", blog_indexer_node)
    
    workflow.set_entry_point("researcher")
    
    # ë¦¬ì„œì²˜ ì´í›„ ì¡°ê±´ë¶€ ë¶„ê¸°
    workflow.add_conditional_edges(
        "researcher",
        should_continue_from_researcher,
        {"continue_to_seo": "seo_specialist", "end_process": END}
    )
    
    workflow.add_edge("seo_specialist", "writer")
    workflow.add_edge("writer", "blog_indexer")
    
    # ë¸”ë¡œê·¸ ì§€ìˆ˜ ì´í›„ ì¡°ê±´ë¶€ ë¶„ê¸° - ì¬ì‘ì„± ì‹œ writerë¡œ ëŒì•„ê°€ê³ , ì•„ë‹ˆë©´ art_directorë¡œ
    workflow.add_conditional_edges(
        "blog_indexer",
        should_continue_from_indexer,
        {
            "rewrite_post": "writer",  # ì¬ì‘ì„± ì‹œ writerë¡œ ëŒì•„ê°€ê¸°
            "continue_to_art": "art_director"  # ì •ìƒ ì§„í–‰ ì‹œ art_directorë¡œ
        }
    )
    
    workflow.add_edge("art_director", END)
    
    return workflow.compile()
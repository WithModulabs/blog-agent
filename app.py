import os
import streamlit as st
from dotenv import load_dotenv, set_key, find_dotenv
from graph import build_graph

load_dotenv()

def main():
    st.set_page_config(page_title="ğŸ¤– ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ìŠ¤íŒ… ìë™ ìƒì„±ê¸°", layout="wide", initial_sidebar_state="expanded")
    
    with st.sidebar:
        st.header("âš™ï¸ API ë° ëª¨ë¸ ì„¤ì •")
        model_provider = st.selectbox("ì‚¬ìš©í•  LLM ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”", ("OpenAI", "Gemini", "Claude"), key="model_provider")
        openai_key = st.text_input("OpenAI API Key", type="password", value=st.session_state.get("openai_api_key", os.getenv("OPENAI_API_KEY") or ""))
        gemini_key = st.text_input("Google API Key", type="password", value=st.session_state.get("gemini_api_key", os.getenv("GEMINI_API_KEY") or ""))
        anthropic_key = st.text_input("Anthropic API Key", type="password", value=st.session_state.get("anthropic_api_key", os.getenv("ANTHROPIC_API_KEY") or ""))
        tavily_key = st.text_input("Tavily API Key", type="password", value=st.session_state.get("tavily_api_key", os.getenv("TAVILY_API_KEY") or ""))
        if st.button("ğŸ’¾ API Keys ì €ì¥"):
            dotenv_path = find_dotenv() or ".env"
            keys_to_save = {
                "OPENAI_API_KEY": openai_key, 
                "GEMINI_API_KEY": gemini_key,
                "ANTHROPIC_API_KEY": anthropic_key,
                "TAVILY_API_KEY": tavily_key
            }
            saved_count = 0
            for key_name, key_value in keys_to_save.items():
                if key_value:
                    st.session_state[key_name.lower()] = key_value
                    set_key(dotenv_path, key_name, key_value)
                    saved_count += 1
            if saved_count > 0:
                st.success(f"âœ… {saved_count}ê°œì˜ API Keyê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ì˜ API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    st.title("ğŸ¤– ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ìŠ¤íŒ… ìë™ ìƒì„±ê¸°")
    st.markdown("ì°¸ê³ í•  ê¸°ì‚¬ë‚˜ ë¸”ë¡œê·¸ ê¸€ì˜ URLì„ ì…ë ¥í•˜ë©´, AI ì—ì´ì „íŠ¸ë“¤ì´ í˜‘ë ¥í•˜ì—¬ **ë„¤ì´ë²„ SEOì— ìµœì í™”ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸**ë¥¼ ìë™ìœ¼ë¡œ ë§Œë“¤ì–´ ë“œë¦½ë‹ˆë‹¤.")

    url = st.text_input("ë¶„ì„í•  ê¸°ì‚¬ ë˜ëŠ” ë¸”ë¡œê·¸ URLì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="https://...")

    if st.button("ğŸš€ ë¸”ë¡œê·¸ ê¸€ ìƒì„± ì‹œì‘!"):
        if not url:
            st.warning("URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        required_key = "openai_api_key" if st.session_state.model_provider == "OpenAI" else ("gemini_api_key" if st.session_state.model_provider == "Gemini" else "anthropic_api_key")
        if not st.session_state.get(required_key):
            st.error(f"âŒ {st.session_state.model_provider} API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥ í›„ ì €ì¥í•´ì£¼ì„¸ìš”.")
            return
        if not st.session_state.get("tavily_api_key"):
            st.error("âŒ Tavily API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥ í›„ ì €ì¥í•´ì£¼ì„¸ìš”.")
            return

        with st.spinner("AI ë©€í‹°ì—ì´ì „íŠ¸ê°€ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤..."):
            app = build_graph()
            initial_state = {"url": url}
            final_state = app.invoke(initial_state)
            st.session_state.final_state = final_state

    if 'final_state' in st.session_state:
        final_state = st.session_state.final_state
        if "ë¶„ì„ ì‹¤íŒ¨:" in final_state.get('scraped_content', ''):
            st.error("ìƒì„± í”„ë¡œì„¸ìŠ¤ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return

        st.divider()
        st.header("âœ¨ ìµœì¢… ê²°ê³¼ë¬¼ âœ¨")

        st.subheader("ğŸ–¼ï¸ ìƒì„±ëœ ì´ë¯¸ì§€")
        all_image_urls = []
        all_image_prompts = []
        image_keywords = final_state.get('image_keywords', ['í‚¤ì›Œë“œ1', 'í‚¤ì›Œë“œ2'])
        keywords_str = '_'.join(image_keywords)
        
        if final_state.get("image_url"):
            all_image_urls.append(final_state["image_url"])
            all_image_prompts.append(final_state.get("image_prompt", ""))
        
        subtitle_urls = final_state.get("subtitle_image_urls", [])
        subtitle_prompts = final_state.get("subtitle_image_prompts", [])
        all_image_urls.extend(subtitle_urls)
        all_image_prompts.extend(subtitle_prompts)
        
        if all_image_urls:
            cols = st.columns(2)
            for i, (u, prompt) in enumerate(zip(all_image_urls, all_image_prompts)):
                with cols[i % 2]:
                    st.image(u, caption=f"ì´ë¯¸ì§€ {i+1}: {prompt[:50]}...")
            st.write("---")
            st.subheader("ğŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ")
            if f'zip_data_{keywords_str}' not in st.session_state:
                import requests, zipfile, io
                with st.spinner("ZIP íŒŒì¼ ì¤€ë¹„ ì¤‘..."):
                    buf = io.BytesIO()
                    with zipfile.ZipFile(buf, 'w', zipfile.ZIP_DEFLATED) as zf:
                        for i, u in enumerate(all_image_urls, 1):
                            try:
                                r = requests.get(u)
                                if r.status_code == 200:
                                    zf.writestr(f"{keywords_str}_{i}.png", r.content)
                            except Exception as e:
                                st.error(f"ì´ë¯¸ì§€ {i} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                    buf.seek(0)
                    st.session_state[f'zip_data_{keywords_str}'] = buf.getvalue()
                    st.success("âœ… ZIP íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ!")
            st.download_button(
                label="ğŸ“¦ ZIP íŒŒì¼ë¡œ ëª¨ë“  ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ",
                data=st.session_state[f'zip_data_{keywords_str}'],
                file_name=f"{keywords_str}_images.zip",
                mime="application/zip",
                help="í´ë¦­í•˜ë©´ ëª¨ë“  ì´ë¯¸ì§€ê°€ ZIP íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤."
            )
        else:
            st.warning("ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆê±°ë‚˜, ìƒì„± ê³¼ì •ì´ ìƒëµë˜ì—ˆìŠµë‹ˆë‹¤.")

        st.subheader("ğŸ“ ì¶”ì²œ ì œëª©")
        st.code(final_state.get('final_title', 'ì œëª© ìƒì„± ì‹¤íŒ¨'), language=None)
        
        st.subheader("ğŸ“‹ ë„¤ì´ë²„ SEO ìµœì í™” ë¶€ì œëª©")
        subtitles = final_state.get('naver_seo_subtitles', [])
        if subtitles:
            all_subtitles = "\n".join([f"{i}. {subtitle}" for i, subtitle in enumerate(subtitles[:5], 1)])
            st.text_area("ìƒì„±ëœ ë¶€ì œëª© (ì „ì²´ ì„ íƒ í›„ ë³µì‚¬)", value=all_subtitles, height=150, key="all_subtitles")
        else:
            st.info("ë¶€ì œëª©ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        st.subheader("ğŸ”– ì¶”ì²œ íƒœê·¸")
        tags_str = ", ".join([f"#{tag}" for tag in final_state.get('seo_tags', []) if tag])
        st.code(tags_str, language=None)
        
        st.subheader("âœï¸ ì™„ì„±ëœ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ (ë§ˆí¬ë‹¤ìš´)")
        blog_content = final_state.get('draft_post', 'í¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨')
        st.text_area("ì „ì²´ ì„ íƒ í›„ ë³µì‚¬í•˜ì„¸ìš” (Ctrl+A â†’ Ctrl+C)", value=blog_content, height=400, key="blog_post_copy")
        with st.expander("ğŸ“– ë§ˆí¬ë‹¤ìš´ ë¯¸ë¦¬ë³´ê¸°"):
            st.markdown(blog_content)
        with st.expander("ğŸ¤– ì—ì´ì „íŠ¸ ì‘ì—… ìƒì„¸ ë‚´ìš© ë³´ê¸°"):
            st.write("**SEO ì „ë¬¸ê°€ ë¶„ì„:**")
            st.text(final_state.get('seo_analysis', 'ë¶„ì„ ë‚´ìš© ì—†ìŒ'))

if __name__ == "__main__":
    main()